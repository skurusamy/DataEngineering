{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-macosx_10_9_x86_64.whl (11.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.0 MB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2017.3\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Collecting numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\"\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-macosx_10_9_x86_64.whl (16.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.9 MB 21.0 MB/s eta 0:00:01    |████████▍                       | 4.4 MB 21.0 MB/s eta 0:00:01     |████████▉                       | 4.7 MB 21.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /Users/subhakuru/Library/Python/3.7/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/subhakuru/Library/Python/3.7/lib/python/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, numpy, pandas\n",
      "Successfully installed numpy-1.21.6 pandas-1.3.5 pytz-2023.3\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask[complete] in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (2022.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/subhakuru/Library/Python/3.7/lib/python/site-packages (from dask[complete]) (23.1)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from dask[complete]) (0.12.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from dask[complete]) (2023.1.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from dask[complete]) (2.2.1)\n",
      "Requirement already satisfied: partd>=0.3.10 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from dask[complete]) (1.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from dask[complete]) (6.0)\n",
      "Collecting distributed==2022.02.0; extra == \"complete\"\n",
      "  Downloading distributed-2022.2.0-py3-none-any.whl (837 kB)\n",
      "\u001b[K     |████████████████████████████████| 837 kB 3.4 MB/s eta 0:00:0100:01\n",
      "\u001b[?25hCollecting jinja2; extra == \"complete\"\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 25.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18; extra == \"complete\" in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from dask[complete]) (1.21.6)\n",
      "Collecting bokeh>=2.1.1; extra == \"complete\"\n",
      "  Downloading bokeh-2.4.3-py3-none-any.whl (18.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 18.5 MB 15.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.0; extra == \"complete\" in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from dask[complete]) (1.3.5)\n",
      "Requirement already satisfied: locket in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from partd>=0.3.10->dask[complete]) (1.0.0)\n",
      "Requirement already satisfied: psutil>=5.0 in /Users/subhakuru/Library/Python/3.7/lib/python/site-packages (from distributed==2022.02.0; extra == \"complete\"->dask[complete]) (5.9.5)\n",
      "Collecting sortedcontainers!=2.0.0,!=2.0.1\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting click>=6.6\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 19.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/subhakuru/Library/Python/3.7/lib/python/site-packages (from distributed==2022.02.0; extra == \"complete\"->dask[complete]) (68.0.0)\n",
      "Requirement already satisfied: tornado>=5; python_version < \"3.8\" in /Users/subhakuru/Library/Python/3.7/lib/python/site-packages (from distributed==2022.02.0; extra == \"complete\"->dask[complete]) (6.2)\n",
      "Collecting tblib>=1.6.0\n",
      "  Downloading tblib-2.0.0-py3-none-any.whl (11 kB)\n",
      "Collecting zict>=0.1.3\n",
      "  Downloading zict-2.2.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting msgpack>=0.6.0\n",
      "  Downloading msgpack-1.0.5-cp37-cp37m-macosx_10_9_x86_64.whl (72 kB)\n",
      "\u001b[K     |████████████████████████████████| 72 kB 1.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.3-cp37-cp37m-macosx_10_9_x86_64.whl (13 kB)\n",
      "Collecting pillow>=7.1.0\n",
      "  Downloading Pillow-9.5.0-cp37-cp37m-macosx_10_10_x86_64.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 22.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions>=3.10.0\n",
      "  Using cached typing_extensions-4.7.0-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/subhakuru/Library/Python/3.7/lib/python/site-packages (from pandas>=1.0; extra == \"complete\"->dask[complete]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas>=1.0; extra == \"complete\"->dask[complete]) (2023.3)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Using cached importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
      "Collecting heapdict\n",
      "  Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/subhakuru/Library/Python/3.7/lib/python/site-packages (from python-dateutil>=2.7.3->pandas>=1.0; extra == \"complete\"->dask[complete]) (1.16.0)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Installing collected packages: sortedcontainers, MarkupSafe, jinja2, typing-extensions, zipp, importlib-metadata, click, tblib, heapdict, zict, msgpack, distributed, pillow, bokeh\n",
      "Successfully installed MarkupSafe-2.1.3 bokeh-2.4.3 click-8.1.3 distributed-2022.2.0 heapdict-1.0.1 importlib-metadata-6.7.0 jinja2-3.1.2 msgpack-1.0.5 pillow-9.5.0 sortedcontainers-2.4.0 tblib-2.0.0 typing-extensions-4.7.0 zict-2.2.0 zipp-3.15.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install dask\\[complete\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 310.8 MB 30 kB/s  eta 0:00:0112 |▎                               | 2.4 MB 626 kB/s eta 0:08:12     |█▎                              | 12.5 MB 934 kB/s eta 0:05:20     |█▌                              | 14.6 MB 934 kB/s eta 0:05:17:22     |██▉                             | 27.7 MB 13.6 MB/s eta 0:00:21     |█████▊                          | 55.7 MB 29.0 MB/s eta 0:00:09     |██████▏                         | 59.9 MB 29.0 MB/s eta 0:00:099.0 MB/s eta 0:00:096.7 MB/s eta 0:00:07     |██████████████████▉             | 182.7 MB 105.5 MB/s eta 0:00:02�████████████████████▋      | 248.2 MB 8.0 MB/s eta 0:00:08�████████████████████▋      | 249.0 MB 8.0 MB/s eta 0:00:08     |██████████████████████████████  | 292.2 MB 586 kB/s eta 0:00:32�███████████████▎ | 294.5 MB 586 kB/s eta 0:00:28███████▍ | 295.1 MB 2.6 MB/s eta 0:00:06     |███████████████████████████████▉| 309.2 MB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting py4j==0.10.9.7\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[K     |████████████████████████████████| 200 kB 5.0 MB/s eta 0:00:01\n",
      "\u001b[?25hUsing legacy setup.py install for pyspark, since package 'wheel' is not installed.\n",
      "Installing collected packages: py4j, pyspark\n",
      "    Running setup.py install for pyspark ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed py4j-0.10.9.7 pyspark-3.4.1\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"/Users/subhakuru/Documents/data/nyse_all/nyse_data/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas processing (452691, 6)\n",
      "pandas processing (759147, 6)\n",
      "pandas processing (37708, 6)\n",
      "pandas processing (478583, 6)\n",
      "pandas processing (414139, 6)\n",
      "pandas processing (329775, 6)\n",
      "pandas processing (638134, 6)\n",
      "pandas processing (306928, 6)\n",
      "pandas processing (278396, 6)\n",
      "pandas processing (524214, 6)\n",
      "pandas processing (358650, 6)\n",
      "pandas processing (429757, 6)\n",
      "pandas processing (702632, 6)\n",
      "pandas processing (470968, 6)\n",
      "pandas processing (794807, 6)\n",
      "pandas processing (382896, 6)\n",
      "pandas processing (294400, 6)\n",
      "pandas processing (317427, 6)\n",
      "pandas processing (569725, 6)\n",
      "pandas processing (498658, 6)\n",
      "pandas processing (345104, 6)\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    df = pd.read_csv(file, names=[\n",
    "        'stock_id','trans_date','open_price','low_price','high_price','volume'\n",
    "    ])\n",
    "    print(\"pandas processing\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-8d2dc956-90e8-419c-bdcd-2839c33a7257')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-64bd42af-e4f6-4d05-aa66-e553fc22ee05')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-1245fea7-280d-4dd9-97db-b69a725dda0f')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-3d634aec-5a42-41e3-b48c-b47800b4c3f3')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-fa5f2ce4-d98e-41ed-a63d-0ad2e26c6fd5')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-190bee61-4aea-4b9e-922e-08fd7e93bd00')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-cbb0cc30-20a5-437e-8685-922673638591')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-dc9cf649-65b4-440c-9c96-ad643fd21e4b')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-8a6d762b-7010-4f3a-8621-abf8843cc4b9')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-d2965bd9-b043-449f-91bf-85048c4e3b37')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-7c13d7a1-20ff-4206-a84e-bc7bf24a7168')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-c4b2d0c1-bcb8-4b38-b721-870c8394c717')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-abeaf65f-e209-444c-abdb-ab603c0fde2c')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-cca3ce7c-2557-4413-beb5-4b8c58ff91c8')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-3748249f-719e-4066-b831-210e6c3d8666')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-844b43e1-d539-4062-bdad-803f6e134c0e')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-6993ba00-6985-408a-81a9-2d91f600562d')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-e0f8474e-86c5-4eab-8c6d-c979e6a4714b')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-268efbb3-b850-40e4-9a82-1aca1462f705')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-7f4d24da-8c17-4c63-8891-140402a75ae7')>\n",
      "pandas processing <bound method DaskMethodsMixin.compute of Delayed('int-072ecf65-a52a-461e-9124-72668088a74e')>\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    df = dd.read_csv(file, names=[\n",
    "        'stock_id','trans_date','open_price','low_price','high_price','volume'\n",
    "    ])\n",
    "    print(\"Dask processing\", df.shape[0].compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/03 09:43:57 WARN Utils: Your hostname, Subhasrees-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.148 instead (on interface en0)\n",
      "23/07/03 09:43:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/03 09:43:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9384739"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#craete spark context as below\n",
    "spark = SparkSession.builder.appName(\"NYSE count\").master(\"local\").getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"/Users/subhakuru/Documents/data/nyse_all/nyse_data/*\")\n",
    "df.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas only uses one process to process the data whereas \n",
    "Dask will automatically uses full system to process data in distributed fashion (even without using chunksize)\n",
    "\n",
    "Pyspark -  more useful for distributed computation. spark works on Dask clusters with multiple nodes seemlessly\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
